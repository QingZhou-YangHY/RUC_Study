# Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning  
具有可验证奖励的强化学习（RLVR）已成为增强大型语言模型（LLM）推理能力的一种强大方法，但其机制尚未得到很好的理解。在这项工作中，通过令牌熵模式的新视角对RLVR进行了开创性的探索，全面分析了不同令牌如何影响推理性能。通过检查思维链（CoT）推理中的令牌熵模式，我们观察到只有一小部分令牌表现出高熵，这些令牌充当关键分叉，引导模型走向不同的推理路径。此外，研究RLVR训练过程中熵模式的演变表明，RLVR在很大程度上遵循基础模型的熵模式，主要是调整高熵令牌的熵。这些发现突显了高熵令牌（即分叉令牌）对RLVR的重要性。  
这些发现表明，RLVR的功效主要来自优化决定推理方向的高熵令牌。总的来说，我们的结果突出了通过令牌熵的角度理解RLVR的潜力，并通过利用高熵少数令牌来优化RLVR，以进一步改进LLM推理。  
## 这种结论一般说自己局限性都是说因为特定情况，但是可以拓展到其他xxx