细粒度，能够找出具体错误的那一部分,复杂的推理任务数学推理，而不是实例级奖励
Token-Level Rewards，最小编辑约束的强化学习（RLMEC）
消融实验：控制变量  
局限性：首先，在这项工作中专注于复杂的推理任务，只对QA任务和数学任务进行实验。RLMEC也可以用于其他场景，例如人类对齐和减少幻觉，这在这项工作中尚未得到验证  
其次，由于计算资源的限制，只评估了RLMEC在7B和13B LLM上的性能，而没有在更大的LLM上进行实验。实际上，通过比较基线方法和RLMEC在7B和13B LLM上的性能，可以观察到RLMEC的有效性。  
第三，方法主要侧重于在复杂的推理任务中增强LLM，而没有考虑使用LLM时可能存在的偏见和伦理风险。这也是我们的RLMEC可以应用的一个有前景的方向，我们将在未来对其进行研究。